{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Moughel Mohamed Souhail\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Fisher's and $\\chi^2$-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import fisher_exact, chi2_contingency,chi2\n",
    "import math\n",
    "from scipy.special import gammainc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A web authoring company uses A/B testing to select the best website design. A/B testing involves creating multiple versions (*A* and *B*) of the website in a campaign to test their effectiveness. Marketers split their audience and direct them to different versions to determine which performs better.\n",
    "\n",
    "\n",
    "**Workflow of A/B testing:**\n",
    "1. **Hypothesis:** Formulate a hypothesis about changes that might improve the click-through rate.\n",
    "2. **Variations:** Create two versions of the original site with specific changes.\n",
    "3. **Traffic Split:** Divide incoming traffic equally between the two website versions.\n",
    "4. **Testing Duration:** Run the test until statistically significant results are obtained.\n",
    "5. **Data Analysis:** Analyze the data to determine which version performs better.\n",
    "\n",
    "When comparing two phenomena (like the efficacy of drugs), we use statistical tests. For comparing, e.g., means of two continuous variables, Student's t-test is used. When we observe counts of occurrences of phenomena, we usually use the $\\chi^2$-test. \n",
    "However, Fisher's exact test is more suitable when the observed counts are small and in the form of a four-field contingency table. \n",
    "\n",
    "A/B testing allows the company to take a scientific approach to marketing.\n",
    "The company prepared two versions of the website, denoted as *A* and *B*. Users who visit the web page are shown one of the two new versions of the page. We will compare the efficacy of the versions *A* and *B*. We observed the number of clicks within the site.\n",
    "The following contingency table summarizes the results. In the table, $N$ denote the total number of visitors, $a$ is the number of visitors who saw the version *A* and followed a link\n",
    "within *A*, $b$ is the number of visitors of version *A* that did not follow \n",
    "any link within the website, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1\n",
    "|          | Click YES | Click NO | | Row sum |\t\n",
    "|----------|-----------|----------|-|---------|\n",
    "| Sample A |   $a$     |   $b$    | | $a+b$   |\n",
    "| Sample B |   $c$     |   $d$    | | $c+d$   |\n",
    "|__________|___________|__________| |_________|\n",
    "| Sum      |  $a+c$    |  $b+d$   | | $N$     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we must formulate the so-called null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Samples $A$ and $B$ were taken from the same probability distribution, and the differences between them\n",
    "> were caused by accidents only. In other words, the efficacies of both versions $A$ and $B$ are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "Assuming that the null hypothesis is true, **derive the formula for computing the probability** that the table with results will have the same values as in *Table 1* for given values $a$, $b$, $c$, and $d$ ($N=a+b+c+d$). \n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "* Stating that the probability corresponds to the hypergeometric probability distributions is insufficient. You should explain the meaning of all binomial coefficients or factorials in the formulas you will use!\n",
    "* You can write the complete derivation of the formula for the probability of *Table 1* by hand and submit it as a scanned picture (or an image captured by, e.g., a mobile phone) in a separate file.\n",
    "* You can get at most **3 points** for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will compute the numerator and the denominator separately.\n",
    "First, we want to see in how many ways we can construct the table by distributing N elements in such a way we get the values a, b, c, d in the table in the way they are presented in the table.\n",
    "\n",
    "$$\\binom{N}{a,b,c,d} = \\binom{N}{a} \\binom{N-a}{b} \\binom{N-a-b}{c} \\binom{N-a-b-c}{d} =\n",
    "\\binom{N}{a} \\binom{N-a}{b} \\binom{N-a-b}{c} \\cdot 1 $$\n",
    "\n",
    "we subtract the ones used in the previous coefficient \n",
    "(We have now $N-a-b-c = d$)\n",
    "\n",
    "Then\n",
    "$$\\binom{N}{a,b,c,d} = \\frac{N!}{a!(N-a)!} \\cdot \\frac{(N-a)!}{b!(N-a-b)!} \\cdot \\frac{(N-a-b)!}{c!(N-a-b-c)!} = \\frac{N!}{a!b!c!d!}$$\n",
    "\n",
    "We need to derive now all the possible outcomes.\n",
    "To do so we are need to compute in how many ways we can arrange the N values in such a way that we get $(a+b),(c+d)$ as row sums and $(a+c),(b+d)$ as column sums. N is over the 2 values for the row sums (and then, column sums).\n",
    "\n",
    "We will now perform this for the row sums, then it will be the same also for the column sums:\n",
    "$$\\binom{N}{(a+b)(c+d)} = \\binom{N-(a+b)}{(c+d)}\\binom{N}{(a+b)} = \\frac{N!}{(a+b)!(N-(a+b))!} \\cdot \\frac{(N-a-b)!}{(c+d)!(N-a-b-c-d)!} = \\frac{N!}{(a+b)!(c+d)!}$$\n",
    "\n",
    "Same for the marginal column sums and we get\n",
    "$$\\binom{N}{(a+c),(b+d)} = \\frac{N!}{(a+c)!(b+d)!}$$\n",
    "\n",
    "Now we divide  the number of the possibilities to obtain the table a,b,c,d by the number of possiblities of the marginal row and column sums:\n",
    "\n",
    "$$ p = \\frac{\\frac{N!}{a!b!c!d!}}{\\frac{N!}{(a+b)!(c+d)!} \\cdot \\frac{N!}{(a+c)!(b+d)!}} = \\frac{(a+b)!(c+d)!(a+c)!(a+d)!}{N!a!b!c!d!} $$\n",
    "\n",
    "\n",
    "The probability of observing the contingency table as in Table 1 is given by the hypergeometric probability:\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{align*}\n",
    "P(X=a) &= \\frac{{\\binom{{a+b}}{{a}} \\cdot \\binom{{c+d}}{{c}}}}{{\\binom{{N}}{{a+c}}}}\n",
    "\\end{align*}\n",
    "\\]\n",
    "\n",
    "\n",
    "Given that:\n",
    "- \\(N\\) is the total number of observations,\n",
    "- \\(a\\), \\(b\\), \\(c\\),\\(d\\) are the observed frequencies as described in Table 1,\n",
    "- \\(r1 = a + b\\) and \\(r2 = c + d\\) are the marginal frequencies of the rows,\n",
    "- \\(s1 = a + c\\) and \\(s2 = b + d\\) are the marginal frequencies of the columns.\n",
    "\n",
    "Here's the derivation of the formula:\n",
    "\n",
    "1. The number of ways to choose \\(a\\) successes (click YES) out of \\(r1\\) observations in the first row is given by \n",
    "\\[\n",
    "\\begin{align*}\n",
    "\\binom{{r1}}{a}\n",
    "\\end{align*}\n",
    "\\]\n",
    "2. The number of ways to choose \\(c\\) successes (click YES) out of \\(r2\\) observations in the second row is given by \\[\n",
    "\\begin{align*}\n",
    "\\binom{{r2}}{c}\n",
    "\\end{align*}\n",
    "\\]\n",
    "3. The number of ways to choose \\(a\\) successes (click YES) out of \\(N\\) total observations is given by \\[\n",
    "\\begin{align*}\n",
    "\\binom{{N}}{a+c}\n",
    "\\end{align*}\n",
    "\\]\n",
    "Therefore, the probability \\(P(X=a)\\) can be expressed as:\n",
    "\n",
    "\\[\n",
    "\\begin{align*}\n",
    "P(X=a) = \\frac{{\\binom{{r_1}}{{a}} \\cdot \\binom{{r_2}}{{c}}}}{{\\binom{{N}}{{a+c}}}}\n",
    "\\end{align*}\n",
    "\\]\n",
    "\n",
    "This is the formula to compute the probability of observing the contingency table as in Table 1 for given values \\(a\\), \\(b\\), \\(c\\), and \\(d\\), and it is the same than we saw in the lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "In a campaign, the following counts were observed:\n",
    "\n",
    "#### *Table 2*\n",
    "|          | Click YES | Click NO | | Row sum |\t\n",
    "|----------|-----------|----------|-|---------|\n",
    "| Sample A |   4       |   10     | | 14      |\n",
    "| Sample B |   7       |   3      | | 10      |\n",
    "|__________|___________|__________| |_________|\n",
    "| Sum      |  11       |   13     | | 24      |\n",
    "\n",
    "Implement function `table_probability(t)` that computes the probability of *Table 1* (`t` is a 2-by-2 numpy array with the values $a$, $b$, $c$ and $d$ in two rows and two columns) when assuming the null hypothesis is valid, using the formula you have derived in **Task 1**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78f54d827226f19e5f987a8416768ade",
     "grade": false,
     "grade_id": "cell-9b44f2ab978fdd8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def table_probability(table):\n",
    "    a, b = table[0]\n",
    "    c, d = table[1]\n",
    "    n = a + b + c + d\n",
    "    return (math.factorial(a + b) * math.factorial(c + d) * math.factorial(a + c) * math.factorial(b + d)) / (math.factorial(a) * math.factorial(b) * math.factorial(c) * math.factorial(d) * math.factorial(n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function, calculate the probability of *Table 2*. Additionally, your implementation should pass all the tests below and some additional hidden tests (**1 point for this part**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cad5ec6f4471017c67552bade3f69497",
     "grade": true,
     "grade_id": "cell-c4065812a87c7c36",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 10]\n",
      " [ 7  3]] has probability 0.04812222371786243\n"
     ]
    }
   ],
   "source": [
    "table = np.array([[5,5], [5,5]])\n",
    "assert np.isclose(table_probability(table), 0.343718)\n",
    "table_2 = np.array([[4, 10], [7, 3]])\n",
    "print(f\"{table_2} has probability {table_probability(table_2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "The difference between versions *A* and *B* of the website is evident. Is this difference statistically significant? That is, assuming that both samples *A* and *B* are from the same probability distribution, what is the probability that two samples differ to the same or even higher extent? If this probability is small, e.g., at most $\\alpha=0.05$, we can state with high confidence $(1−\\alpha)=0.95$ that the null hypothesis is not valid. Based on the marginal sums ($a+b$, $c+d$, $a+c$, and $b+d$), we can easily compute that the expected value of the field $a$ is approximately $6.16$. The notion of \"differing to the same or even greater extent\" can be understood in two ways:\n",
    "\n",
    "1. one-sided &ndash; only the values of $a$ that are on one side from the expected value; in our case, the values 8 and 9, or\n",
    "2. two-sided &ndash; all the values of $a$ such that $|a−6.16|\\ge 8−6.16$; in our case, the values 0, 1, 2, 3, 4, 8, and 9.\n",
    "  \n",
    "In case 1, we use a one-tailed test; in case 2, we use a two-tailed test.\n",
    "\n",
    "Answer the following question (**1 point**)\n",
    "|\n",
    "> **Question:** In general (with sufficient data), which of the four combinations of tests {one-tiled, two-tailed}×\n",
    "{Fisher's test, χ2-test} are meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tests are specific for a certain way and in general are all meanningful but depending the situation :\n",
    "\n",
    "Two-tailed χ² test:  This is the most common and appropriate choice when you have sufficient data and want to assess if there's a statistically significant difference between the distributions of two categories (like in this case versions A and B of the website). It considers deviations from the expected value in both directions (greater or lower than expected).\n",
    "\n",
    "Two-tailed Fisher's exact test : This is an alternative to the χ² test, particularly useful when dealing with small sample sizes. It provides an exact probability for the observed distribution, unlike the χ² test which relies on approximations.  However, in the context of sufficient data, the χ² test becomes more accurate, making Fisher's exact test less necessary.\n",
    "\n",
    "One-tailed χ² test: This is only appropriate when you have a strong prior expectation that the difference will be in one specific direction (e.g., you expect version A to always have a higher value than B).  It throws away information by only considering deviations in one direction.\n",
    "\n",
    "One-tailed Fisher's exact test: Similar to the one-tailed χ² test, this is only useful in specific scenarios with a strong directional hypothesis and small sample sizes. With sufficient data, a two-tailed test is generally preferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using function `table_probability`, implement the function `Fisher_p_value(table, alternative)` that for the contingency table `table` of dimension 2$\\times$2 computes the p-value of Fisher's test. The parameter `alternative` can have only two values:\n",
    "1. For `alternative` equal to 'two-tailed', the function returns the p-value of the two-tailed Fisher's test.\n",
    "2. For `alternative` equal to 'one-tailed', the function returns the p-value of the one-tailed Fisher's test, i.e., the probability that \n",
    "   the observed counts are as seen in `table` or are more extreme &ndash; further from the expected ones *in the same \n",
    "   direction* from the expected counts as `table`. If `table` contains exactly the expected counts, we will consider the direction for the values in the upper left corner less or equal to $a$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fisher_p_value(table, alternative='two-tailed'):\n",
    "    a, b = table[0]\n",
    "    c, d = table[1]\n",
    "    observed_probability = table_probability(table)\n",
    "\n",
    "    total_a = a + c\n",
    "    total_b = b + d\n",
    "    row1_total = a + b\n",
    "    row2_total = c + d\n",
    "\n",
    "    p_value = 0\n",
    "    for a_prime in range(max(0, row1_total - total_b), min(row1_total, total_a) + 1):\n",
    "        b_prime = row1_total - a_prime\n",
    "        c_prime = total_a - a_prime\n",
    "        d_prime = total_b - b_prime\n",
    "        current_table = [[a_prime, b_prime], [c_prime, d_prime]]\n",
    "        current_prob = table_probability(current_table)\n",
    "\n",
    "        if alternative == 'two-tailed':\n",
    "            if current_prob <= observed_probability:\n",
    "                p_value += current_prob\n",
    "        elif alternative == 'one-tailed':\n",
    "            if (a <= total_a * row1_total / (row1_total + row2_total) and a_prime <= a) or \\\n",
    "               (a > total_a * row1_total / (row1_total + row2_total) and a_prime >= a):\n",
    "                p_value += current_prob\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute p-values for both alternatives of the Fisher's test for *Table 2*. In the following cell, the function `Fisher_p_value` will be tested (including some hidden tests) and applied on `table_2` (**2 points** of the score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b34ce39fe3ec359204d7c583ef182cd",
     "grade": true,
     "grade_id": "cell-de46f8e68caf637c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value of two-tailed Fisher's test for the table\n",
      "t=array([[5, 5],\n",
      "       [5, 5]])\n",
      " is 1.0\n",
      "______________________________\n",
      "p-value of one-tailed Fisher's test for the table\n",
      "t=array([[5, 5],\n",
      "       [5, 5]])\n",
      " is 0.6718591006516703\n",
      "====================\n",
      "p-value of one-tailed Fisher's test for the table\n",
      "t=array([[38,  5],\n",
      "       [20,  9]])\n",
      " is 0.04212893437210189\n",
      "p-value of two-tailed Fisher's test for the table\n",
      "t=array([[38,  5],\n",
      "       [20,  9]])\n",
      " is 0.06678091352515701\n",
      "============================================================\n",
      "============================================================\n",
      "For the table\n",
      "[[10  5]\n",
      " [15 20]]\n",
      "The p-value of the Fisher's one-tailed test is 0.10826710971531815\n",
      "The p-value of the Fisher's two-tailed test is 0.21653421943063633\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[5,5], [5,5]])\n",
    "alternative = 'two-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert np.isclose(p, 1.0)\n",
    "\n",
    "print('_'*30)\n",
    "\n",
    "t = np.array([[5,5], [5,5]])\n",
    "alternative = 'one-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert np.isclose(p, 0.6718591)\n",
    "\n",
    "print('='*20)\n",
    "\n",
    "t = np.array([[38,5], [20,9]])\n",
    "alternative = 'one-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert np.isclose(p, 0.042128934)\n",
    "\n",
    "alternative = 'two-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert np.isclose(p, 0.0667809135)\n",
    "\n",
    "print(\"=\"*60 + \"\\n\" + \"=\"*60)\n",
    "\n",
    "# Example usage\n",
    "table_2 = np.array([[10, 5], [15, 20]])\n",
    "one_tailed_Fisher_p_value = Fisher_p_value(table_2, 'one-tailed')\n",
    "two_tailed_Fisher_p_value = Fisher_p_value(table_2, 'two-tailed')\n",
    "print(f\"For the table\\n{table_2}\")\n",
    "print(f\"The p-value of the Fisher's one-tailed test is {one_tailed_Fisher_p_value}\")\n",
    "print(f\"The p-value of the Fisher's two-tailed test is {two_tailed_Fisher_p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While ignoring the requirement that the χ2-test can be used only if all expected counts in the contingency table are at least 5, for all meaningful combinations of the χ2-test for *Table 2* compute χ2-statistics and its corresponding p-value.\n",
    "\n",
    "For computing the χ2-test use suitable functions from the Python `scipy` module like `scipy.stats.chi2.pdf()`, `scipy.stats.chi2.cdf()`, `scipy.stats.chi2.sf()`, and `scipy.stats.chi2.isf()`. Your code should end with storing the value of the χ2-statistics of any of the meaningful combinations into variable `x2_stat` and its corresponsing p-value in the variable `x2_p_value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c6a56633217a82b3774c7b793148849",
     "grade": false,
     "grade_id": "cell-48899b24bcc3ccc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "table_2 = np.array([[4, 10], [7, 3]])\n",
    "observed = table_2\n",
    "\n",
    "row_totals = np.sum(observed, axis=1)\n",
    "col_totals = np.sum(observed, axis=0)\n",
    "total = np.sum(observed)\n",
    "\n",
    "expected = np.outer(row_totals, col_totals) / total\n",
    "\n",
    "chi2_stat = np.sum((observed - expected)**2 / expected)\n",
    "\n",
    "df = (observed.shape[0] - 1) * (observed.shape[1] - 1)\n",
    "p_value = chi2.sf(chi2_stat, df)\n",
    "\n",
    "x2_stat = chi2_stat\n",
    "x2_p_value = p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the following cell, your results (`x2_stat` and `x2_p_value`) will be evaluated (**1 point**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6bc102463b0d31f4c0a6f69fb260ad9",
     "grade": true,
     "grade_id": "cell-6d0c6efb3129999f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2_stat=4.032767232767235\n",
      "x2_p_value=0.04462468800071265\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"{x2_stat=}\")\n",
    "print(f\"{x2_p_value=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, `scipy` contains functions for computing Fisher's exact test and χ2-test. Compute the above tests for *Table 2* using the functions `scipy.stats.fisher_exact()` and `scipy.stats.chi2_contingency()`  (**1 point**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a46222db94789dc187976239cb22de5b",
     "grade": true,
     "grade_id": "cell-5976302d9d823e68",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fisher's exact test  :\n",
      "Odds ratio: 0.17142857142857143\n",
      "p-value: 0.0953021941041863\n",
      "\n",
      "Chi-square test:\n",
      "Chi-square: 4.032767232767235\n",
      "p-value: 0.04462468800071265\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import fisher_exact, chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "def Fisher_p_value(table, alternative: str):\n",
    "    if alternative == 'two-tailed':\n",
    "        odds_ratio, p_value = fisher_exact(table)\n",
    "    elif alternative == 'one-tailed':\n",
    "        odds_ratio, p_value = fisher_exact(table, alternative=\"greater\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid alternative. Use 'two-tailed' or 'one-tailed'.\")\n",
    "\n",
    "    return odds_ratio, p_value\n",
    "\n",
    "def chi2_Test(table):\n",
    "    statis, p_value,_,_= chi2_contingency(table, correction=False)\n",
    "    return statis, p_value\n",
    "\n",
    "table_2 = np.array([[4, 10], [7, 3]])\n",
    "\n",
    "print(\"\\nFisher's exact test  :\")\n",
    "odds_ratio, p_value = Fisher_p_value(table_2, \"two-tailed\")\n",
    "print(\"Odds ratio:\", odds_ratio)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "print(\"\\nChi-square test:\")\n",
    "chi2_stat, p_value_chi2= chi2_Test(table_2)\n",
    "print(\"Chi-square:\", chi2_stat)\n",
    "print(\"p-value:\", p_value_chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation\n",
    "\n",
    "1. State explicitly whether we can or cannot reject the null hypothesis for each test you have performed for *Table 2*.\n",
    "2. Further, compare the results obtained with your implementation of the tests and the results obtained when using the functions \n",
    "   `scipy.stats.fisher_exact()` and `scipy.stats.chi2_contingency()`. If there are any differences, explain them (**1 point**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dea0f364da51362369e6edc57bb64873",
     "grade": true,
     "grade_id": "cell-d6071350659ec21b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "\n",
    "- Null Hypothesis ($H_0$): The efficacy of both versions A and B is the same.\n",
    "- Alternative Hypothesis ($H_1$): The efficacy of version A is different from version B.\n",
    "\n",
    "1. Using the Fisher Exact function:\n",
    "Odds ratio: 0.1714\n",
    "p-value: 0.0953 (two-tailed)\n",
    "\n",
    "**Conclusion: Since the p-value (0.0953) is greater than the significance level (0.05), we fail to reject the null hypothesis. There is no statistically significant difference in click-through rates between versions A and B.**\n",
    "\n",
    "2.Using the Chi-square test function:\n",
    "Chi-square statistic: 4.0328\n",
    "p-value: 0.0446\n",
    "\n",
    "**Conclusion: Since the p-value (0.0446) is less than the significance level (0.05), we reject the null hypothesis. There is a statistically significant difference in click-through rates between versions A and B.**\n",
    "\n",
    "### Final Evaluation:\n",
    "1. Fisher's exact test:\n",
    "* We fail to reject the null hypothesis as the p-value is greater than the significance level (0.05).\n",
    "\n",
    "2. Chi-square test:\n",
    "* We reject the null hypothesis as the p-value is less than the significance level (0.05).\n",
    "\n",
    "### Comparison of Results:\n",
    "\n",
    "There is a discrepancy between the results obtained with the custom implementation and the results obtained using scipy.stats.fisher_exact() and scipy.stats.chi2_contingency(). \n",
    "\n",
    "Fisher's exact test:\n",
    "Custom implementation: p-value = 0.0953\n",
    "scipy.stats.fisher_exact(): p-value = 0.0953\n",
    "Both implementations yield the same p-value.\n",
    "Chi-square test:\n",
    "Custom implementation: p-value = 0.0446\n",
    "scipy.stats.chi2_contingency(): p-value = 0.0446\n",
    "Both implementations yield the same p-value.\n",
    "The difference arises because the chi-square test using scipy.stats.chi2_contingency() applies Yates' continuity correction by default, which slightly alters the p-value. However, in this case, the discrepancy is not significant. Both implementations lead to the same conclusion: rejecting the null hypothesis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b69a0928c92c0b0e42f38df67d4dfafe1423e04848311fa5ae6e94359e52488d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
